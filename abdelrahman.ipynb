{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob as gb\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "\n",
    "from scipy.stats import entropy\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk\n",
    "from skimage.filters import prewitt_h,prewitt_v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = {'NORMAL':0 ,'PNEUMONIA':1}\n",
    "\n",
    "def getcode(n) : \n",
    "    for x , y in code.items() : \n",
    "        if n == y : \n",
    "            return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file path\n",
    "trainpath = 'dataset/train/'\n",
    "testpath = 'dataset/test/'\n",
    "valpath = 'dataset/val/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training data , found 0 in folder .DS_Store\n",
      "For training data , found 1341 in folder NORMAL\n",
      "For training data , found 3875 in folder PNEUMONIA\n",
      "For val data , found 0 in folder .DS_Store\n",
      "For val data , found 234 in folder NORMAL\n",
      "For val data , found 390 in folder PNEUMONIA\n",
      "For testing data , found 0 in folder .DS_Store\n",
      "For testing data , found 8 in folder NORMAL\n",
      "For testing data , found 8 in folder PNEUMONIA\n"
     ]
    }
   ],
   "source": [
    "for folder in  os.listdir(trainpath) : \n",
    "    files = gb.glob(pathname= str( trainpath +'//' + folder + '/*.jpeg'))\n",
    "    print(f'For training data , found {len(files)} in folder {folder}')\n",
    "\n",
    "for folder in  os.listdir(testpath) : \n",
    "    files = gb.glob(pathname= str( testpath +'//' + folder + '/*.jpeg'))\n",
    "    print(f'For val data , found {len(files)} in folder {folder}')\n",
    "    \n",
    "for folder in  os.listdir(valpath) : \n",
    "    files = gb.glob(pathname= str( valpath +'//' + folder + '/*.jpeg'))\n",
    "    print(f'For testing data , found {len(files)} in folder {folder}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have 5216 items in X_train\n",
      "we have 5216 items in X_train\n",
      "we have 5216 items in X_train\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "X_train_half =[]\n",
    "X_train_quar= []\n",
    "for folder in  os.listdir(trainpath) : \n",
    "    files = gb.glob(pathname= str( trainpath +'//' + folder + '/*.jpeg'))\n",
    "    for file in files: \n",
    "        image = cv2.imread(file, 0)\n",
    "        image_array = cv2.resize(image , (s,s))\n",
    "        equalized_img = cv2.equalizeHist(image_array)\n",
    "        mean_img=equalized_img.mean()\n",
    "        median_img=np.median(equalized_img)\n",
    "        std_img=equalized_img.std()\n",
    "        var_img=equalized_img.var()\n",
    "        skew_img=(3*(mean_img-median_img))/std_img\n",
    "        entropy_img=entropy(equalized_img, disk(5)).mean()\n",
    "        prewitt_h_img=prewitt_h(equalized_img).mean()\n",
    "        prewitt_v_img=prewitt_v(equalized_img).mean()\n",
    "        sobelx_img = cv2.Sobel(equalized_img,cv2.CV_64F,1,0,ksize=5).mean()\n",
    "        sobely_img = cv2.Sobel(equalized_img,cv2.CV_64F,0,1,ksize=5).mean()\n",
    "        app=[mean_img,median_img,std_img,var_img,skew_img,entropy_img,prewitt_h_img,prewitt_v_img,sobelx_img,sobely_img ,code[folder]]\n",
    "        half=[mean_img,median_img,std_img,var_img,skew_img ,  code[folder]]\n",
    "        quar=[entropy_img,prewitt_h_img,prewitt_v_img ,  code[folder]]\n",
    "        X_train_half.append(list(half))\n",
    "        X_train_quar.append(list(quar))\n",
    "        X_train.append(list(app))\n",
    "\n",
    "print(f'we have {len(X_train)} items in X_train')\n",
    "print(f'we have {len(X_train_half)} items in X_train')\n",
    "print(f'we have {len(X_train_quar)} items in X_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have 624 items in X_test\n",
      "we have 624 items in X_test\n",
      "we have 624 items in X_test\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "X_test = []\n",
    "X_test_half =[]\n",
    "X_test_quar= []\n",
    "for folder in  os.listdir(testpath) : \n",
    "    files = gb.glob(pathname= str(testpath + '//' + folder + '/*.jpeg'))\n",
    "    for file in files: \n",
    "        image = cv2.imread(file ,0)\n",
    "        image_array = cv2.resize(image , (s,s))\n",
    "        equalized_img = cv2.equalizeHist(image_array)\n",
    "        mean_img=equalized_img.mean()\n",
    "        median_img=np.median(equalized_img)\n",
    "        std_img=equalized_img.std()\n",
    "        var_img=equalized_img.var()\n",
    "        skew_img=(3*(mean_img-median_img))/std_img\n",
    "        entropy_img=entropy(equalized_img, disk(5)).mean()\n",
    "        prewitt_h_img=prewitt_h(equalized_img).mean()\n",
    "        prewitt_v_img=prewitt_v(equalized_img).mean()\n",
    "        sobelx_img = cv2.Sobel(equalized_img,cv2.CV_64F,1,0,ksize=5).mean()\n",
    "        sobely_img = cv2.Sobel(equalized_img,cv2.CV_64F,0,1,ksize=5).mean()\n",
    "        app=[mean_img,median_img,std_img,var_img,skew_img,entropy_img,prewitt_h_img,prewitt_v_img,sobelx_img,sobely_img ,code[folder]]\n",
    "        half=[mean_img,median_img,std_img,var_img,skew_img ,  code[folder]]\n",
    "        quar=[entropy_img,prewitt_h_img,prewitt_v_img ,  code[folder]]\n",
    "        X_test_half.append(list(half))\n",
    "        X_test_quar.append(list(quar))\n",
    "        X_test.append(list(app))\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "print(f'we have {len(X_test)} items in X_test') \n",
    "print(f'we have {len(X_test_half)} items in X_test')\n",
    "print(f'we have {len(X_test_quar)} items in X_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = []\n",
    "files = gb.glob(pathname= str(valpath + '//' + folder + '/*.jpeg'))\n",
    "for file in files: \n",
    "    image = cv2.imread(file ,0)\n",
    "    image_array = cv2.resize(image , (s,s))\n",
    "    equalized_img = cv2.equalizeHist(image_array)\n",
    "    mean_img=equalized_img.mean()\n",
    "    median_img=np.median(equalized_img)\n",
    "    std_img=equalized_img.std()\n",
    "    var_img=equalized_img.var()\n",
    "    skew_img=(3*(mean_img-median_img))/std_img\n",
    "    entropy_img=entropy(equalized_img, disk(5))\n",
    "    prewitt_h_img=prewitt_h(equalized_img).mean()\n",
    "    prewitt_v_img=prewitt_v(equalized_img).mean()\n",
    "    sobelx_img = cv2.Sobel(equalized_img,cv2.CV_64F,1,0,ksize=5).mean()\n",
    "    sobely_img = cv2.Sobel(equalized_img,cv2.CV_64F,0,1,ksize=5).mean()\n",
    "#     app=[mean_img,median_img,std_img,var_img,skew_img, code[folder] ]\n",
    "    app=[mean_img,median_img,std_img,var_img,skew_img,entropy_img,prewitt_h_img,prewitt_v_img,sobelx_img,sobely_img , code[folder]]\n",
    "    X_val.append(list(app))   \n",
    "print(f'we have {len(X_val)} items in X_val')    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>var</th>\n",
       "      <th>skew</th>\n",
       "      <th>entropy</th>\n",
       "      <th>prewitt_h</th>\n",
       "      <th>prewitt_v</th>\n",
       "      <th>sobelx</th>\n",
       "      <th>sobely</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127.841837</td>\n",
       "      <td>129.0</td>\n",
       "      <td>73.961418</td>\n",
       "      <td>5470.291311</td>\n",
       "      <td>-0.046977</td>\n",
       "      <td>5.447845</td>\n",
       "      <td>0.010754</td>\n",
       "      <td>-0.000460</td>\n",
       "      <td>60.335459</td>\n",
       "      <td>205.909439</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118.352041</td>\n",
       "      <td>119.0</td>\n",
       "      <td>78.591644</td>\n",
       "      <td>6176.646475</td>\n",
       "      <td>-0.024734</td>\n",
       "      <td>5.374762</td>\n",
       "      <td>0.010584</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>-8.647959</td>\n",
       "      <td>243.987245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114.275510</td>\n",
       "      <td>113.0</td>\n",
       "      <td>80.298776</td>\n",
       "      <td>6447.893482</td>\n",
       "      <td>0.047654</td>\n",
       "      <td>5.206042</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>-0.000120</td>\n",
       "      <td>5.096939</td>\n",
       "      <td>208.994898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126.956633</td>\n",
       "      <td>127.0</td>\n",
       "      <td>74.628028</td>\n",
       "      <td>5569.342507</td>\n",
       "      <td>-0.001743</td>\n",
       "      <td>5.379261</td>\n",
       "      <td>0.006963</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>-25.077806</td>\n",
       "      <td>128.784439</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114.059949</td>\n",
       "      <td>112.0</td>\n",
       "      <td>80.334157</td>\n",
       "      <td>6453.576763</td>\n",
       "      <td>0.076927</td>\n",
       "      <td>5.316557</td>\n",
       "      <td>0.032203</td>\n",
       "      <td>-0.002701</td>\n",
       "      <td>-17.295918</td>\n",
       "      <td>483.739796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean  median        std          var      skew   entropy  prewitt_h  \\\n",
       "0  127.841837   129.0  73.961418  5470.291311 -0.046977  5.447845   0.010754   \n",
       "1  118.352041   119.0  78.591644  6176.646475 -0.024734  5.374762   0.010584   \n",
       "2  114.275510   113.0  80.298776  6447.893482  0.047654  5.206042   0.010714   \n",
       "3  126.956633   127.0  74.628028  5569.342507 -0.001743  5.379261   0.006963   \n",
       "4  114.059949   112.0  80.334157  6453.576763  0.076927  5.316557   0.032203   \n",
       "\n",
       "   prewitt_v     sobelx      sobely  label  \n",
       "0  -0.000460  60.335459  205.909439      0  \n",
       "1  -0.000100  -8.647959  243.987245      0  \n",
       "2  -0.000120   5.096939  208.994898      0  \n",
       "3   0.001671 -25.077806  128.784439      0  \n",
       "4  -0.002701 -17.295918  483.739796      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['mean','median','std','var','skew','entropy','prewitt_h','prewitt_v','sobelx','sobely','label']\n",
    "\n",
    "f= open('Chest_xray.csv', 'a', newline='')\n",
    "w= csv.writer(f)\n",
    "w.writerows(X_train)\n",
    "w.writerows(X_test)\n",
    "\n",
    "f.close()     \n",
    "pima = pd.read_csv(\"Chest_xray.csv\", header=None, names=col_names)\n",
    "\n",
    "pima.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>var</th>\n",
       "      <th>skew</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127.841837</td>\n",
       "      <td>129.0</td>\n",
       "      <td>73.961418</td>\n",
       "      <td>5470.291311</td>\n",
       "      <td>-0.046977</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118.352041</td>\n",
       "      <td>119.0</td>\n",
       "      <td>78.591644</td>\n",
       "      <td>6176.646475</td>\n",
       "      <td>-0.024734</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114.275510</td>\n",
       "      <td>113.0</td>\n",
       "      <td>80.298776</td>\n",
       "      <td>6447.893482</td>\n",
       "      <td>0.047654</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126.956633</td>\n",
       "      <td>127.0</td>\n",
       "      <td>74.628028</td>\n",
       "      <td>5569.342507</td>\n",
       "      <td>-0.001743</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114.059949</td>\n",
       "      <td>112.0</td>\n",
       "      <td>80.334157</td>\n",
       "      <td>6453.576763</td>\n",
       "      <td>0.076927</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean  median        std          var      skew  label\n",
       "0  127.841837   129.0  73.961418  5470.291311 -0.046977      0\n",
       "1  118.352041   119.0  78.591644  6176.646475 -0.024734      0\n",
       "2  114.275510   113.0  80.298776  6447.893482  0.047654      0\n",
       "3  126.956633   127.0  74.628028  5569.342507 -0.001743      0\n",
       "4  114.059949   112.0  80.334157  6453.576763  0.076927      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names_half = ['mean','median','std','var','skew','label']\n",
    "\n",
    "f= open('chest_xray_half.csv', 'a', newline='')\n",
    "w= csv.writer(f)\n",
    "w.writerows(X_train_half)\n",
    "w.writerows(X_test_half)\n",
    "\n",
    "f.close()     \n",
    "pima_half = pd.read_csv(\"chest_xray_half.csv\", header=None, names=col_names_half)\n",
    "\n",
    "pima_half.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entropy</th>\n",
       "      <th>prewitt_h</th>\n",
       "      <th>prewitt_v</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.447845</td>\n",
       "      <td>0.010754</td>\n",
       "      <td>-0.000460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.374762</td>\n",
       "      <td>0.010584</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.206042</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>-0.000120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.379261</td>\n",
       "      <td>0.006963</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.316557</td>\n",
       "      <td>0.032203</td>\n",
       "      <td>-0.002701</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    entropy  prewitt_h  prewitt_v  label\n",
       "0  5.447845   0.010754  -0.000460      0\n",
       "1  5.374762   0.010584  -0.000100      0\n",
       "2  5.206042   0.010714  -0.000120      0\n",
       "3  5.379261   0.006963   0.001671      0\n",
       "4  5.316557   0.032203  -0.002701      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names_quar = ['entropy','prewitt_h','prewitt_v','label']\n",
    "\n",
    "f= open('chest_xray_quar.csv', 'a', newline='')\n",
    "w= csv.writer(f)\n",
    "w.writerows(X_train_quar)\n",
    "w.writerows(X_test_quar)\n",
    "\n",
    "f.close()     \n",
    "pima_quar = pd.read_csv(\"chest_xray_quar.csv\", header=None, names=col_names_quar)\n",
    "\n",
    "pima_quar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_cols = ['mean','median','std','var','skew','entropy','prewitt_h','prewitt_v','sobelx','sobely']\n",
    "X = pima[feature_cols]\n",
    "Y = pima.label # Target variable\n",
    "\n",
    "\n",
    "feature_cols_half = ['mean','median','std','var','skew']\n",
    "X_half = pima[feature_cols_half]\n",
    "Y_half = pima.label # Target variable\n",
    "\n",
    "feature_cols_quar = ['entropy','prewitt_h','prewitt_v']\n",
    "X_quar = pima[feature_cols_quar]\n",
    "Y_quar = pima.label # Target variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set aside 75% of train and test data for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size=0.25, random_state = 2, shuffle=True)\n",
    "X_train_half, X_test_half, y_train_half, y_test_half = train_test_split(X_half, Y_half,test_size=0.25, random_state = 2, shuffle=True)\n",
    "X_train_quar, X_test_quar, y_train_quar, y_test_quar = train_test_split(X_quar, Y_quar,test_size=0.25, random_state = 2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have 4380 items in X_train\n",
      "we have 1460 items in X_test\n"
     ]
    }
   ],
   "source": [
    "print(f'we have {len(X_train)} items in X_train')  \n",
    "print(f'we have {len(X_test)} items in X_test')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "clf_half = DecisionTreeClassifier()\n",
    "\n",
    "clf_half = clf_half.fit(X_train_half,y_train_half)\n",
    "y_pred_half = clf_half.predict(X_test_half)\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "clf_quar = clf.fit(X_train_quar,y_train_quar)\n",
    "y_pred_quar = clf.predict(X_test_quar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7931506849315069\n",
      "Accuracy half: 0.7321917808219178\n",
      "Accuracy quarter: 0.6801369863013699\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Accuracy half:\",metrics.accuracy_score(y_test_half, y_pred_half))\n",
    "print(\"Accuracy quarter:\",metrics.accuracy_score(y_test_quar, y_pred_quar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.836986 \n",
      "LDA: 0.848630 \n",
      "KNN: 0.736986 \n",
      "CART: 0.799315 \n",
      "NB: 0.708219 \n",
      "SVM: 0.710959 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "#     kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "#     cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    model.fit(X_train,y_train)\n",
    "    cv_results= metrics.accuracy_score(y_test, model.predict(X_test))\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print('%s: %f ' % (name, cv_results.mean()))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "062e2acc2a900d351f08b5486d55b7e359d8164b3ffd854af3df16a595ae0368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
